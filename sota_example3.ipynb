{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SEaUopfhuqq"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF1Clk-4d6vI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUfBCBlCiCbp"
   },
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "QASUd96KeA_2",
    "outputId": "c72ca377-c766-4e56-9576-82d6aebb8289"
   },
   "outputs": [],
   "source": [
    "# Download the digits data\n",
    "! wget https://nyc3.digitaloceanspaces.com/ai-classroom/digits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "S89D4B9ieNE3",
    "outputId": "20e3ba61-7b7c-4083-8c0e-d87a45433665"
   },
   "outputs": [],
   "source": [
    "# Take a look at the raw data\n",
    "! head digits.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFiPJ63EiGMr"
   },
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "rABnNEH5eSTX",
    "outputId": "8e9ed450-efe6-4dcb-eb15-692e4a2aa30b"
   },
   "outputs": [],
   "source": [
    "# Read the data into a dataframe\n",
    "data = pd.read_csv('digits.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "AS2GZSDS-MO1",
    "outputId": "74c2235d-66fd-4acc-af22-e68dd440c837"
   },
   "outputs": [],
   "source": [
    "# Let's see one of these digits\n",
    "for_plot = data[data.columns[1:]].values.reshape(42000,28,28)\n",
    "plt.imshow(for_plot[121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTMzeV9cexMY"
   },
   "outputs": [],
   "source": [
    "# Get just the images portions of the data, as that's all we need.\n",
    "train_images = data[data.columns[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MvvXDnqscRj"
   },
   "outputs": [],
   "source": [
    "# Reshape and normalize the data.\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAohaN2lsjqk"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data.\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0qZaibZjQ15"
   },
   "source": [
    "# Define the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPevpKt4su_0"
   },
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFHMlgqmfADh"
   },
   "outputs": [],
   "source": [
    "# make_generator initializes our generator neural network model\n",
    "def make_generator():\n",
    "\n",
    "  # In TF 2.0+, \"Keras\" is the default API. In Keras, you assemble layers to build models.\n",
    "  # The most common type of model is a stack of layers: the tf.keras.Sequential model.\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  # Add a dense layer to process the seed/ latent/ random input.\n",
    "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  # Start reshaping the data into an image like volume.\n",
    "  model.add(layers.Reshape((7, 7, 256)))\n",
    "  assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "  # We are then going to use some special convolutional layers. These \"transposed\"\n",
    "  # layers can be thought of as a type of \"backwards\" convolutional layer that is\n",
    "  # often used to process something that has the shape of the output of some \n",
    "  # convolution to something that has the shape of its input.\n",
    "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "  assert model.output_shape == (None, 7, 7, 128)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "  assert model.output_shape == (None, 14, 14, 64)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "  assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUNWTjD5nzBG"
   },
   "outputs": [],
   "source": [
    "# Intialize the generator\n",
    "generator = make_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "toCtuHLqgj_Y",
    "outputId": "aaa05bb2-bc06-41bf-e4a3-c72cd67e9965"
   },
   "outputs": [],
   "source": [
    "# Let's try using our generator to generate an output from some random input.\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5iYoH8Uvm0b"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L-rv1KhvvQk"
   },
   "outputs": [],
   "source": [
    "# make_discriminator initializes our discriminator neural network model\n",
    "def make_discriminator():\n",
    "\n",
    "  # In TF 2.0+, \"Keras\" is the default API. In Keras, you assemble layers to build models.\n",
    "  # The most common type of model is a stack of layers: the tf.keras.Sequential model.\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  # Add some typical convolutional layers similar to our other image\n",
    "  # classification problems. The \"Dropout\" here is a method that is used to\n",
    "  # prevent overfitting by randomly dropping out or ignoring the output\n",
    "  # of some nodes.\n",
    "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  # Out dense layer for classification of generated or not generated.\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Im2_Pb1-wWMl"
   },
   "outputs": [],
   "source": [
    "# initialize our discriminator.\n",
    "discriminator = make_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TKHN13Nwe2o"
   },
   "source": [
    "## Define our losses and training related information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s74qyh9RwlMG"
   },
   "outputs": [],
   "source": [
    "# Define cross_entropy loss so that we can utilize it for a custom loss function\n",
    "# defined below.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# This special loss compares the discriminator's predictions on real images to \n",
    "# an array of 1's, and the discriminator's predictions on generated images to an \n",
    "# array of 0s.\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# For the generator, we only compare discriminators decisions on the generated \n",
    "# images to an array of 1's, because we only care about how well the generator\n",
    "# did in \"fooling\" the discriminator.\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wGkI67FxLSB"
   },
   "outputs": [],
   "source": [
    "# Use adam optimizers for both models.\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClCyIek0xV5q"
   },
   "outputs": [],
   "source": [
    "# This training is going to run a bit longer, so we are going to save \n",
    "# checkpoints. This is a great idea for longer training runs, just in case \n",
    "# something goes wrong in the middle.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTUtewwRxjcN"
   },
   "outputs": [],
   "source": [
    "# Define some training parameters.\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# Create a particular random seed that we will use over and over during training\n",
    "# to visualize the output images that are being generated.\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJ0fqbBdKUwJ"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8SQRFKMx1ES"
   },
   "outputs": [],
   "source": [
    "# We are going to define a custom training step for the GAN training. In this \n",
    "# case we are going to opt NOT to use eager mode in TensorFlow. Using the\n",
    "# @tf.function decorator here will cause our computations to be compiled\n",
    "# into a computational graph before any computations are made. This allows\n",
    "# the compiler to optimize things and speed up the process. \n",
    "@tf.function\n",
    "def train_step(images):\n",
    "\n",
    "  # Create random input for our Generator.\n",
    "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  # As opposed to our examples with PyTorch, we need to implement some special\n",
    "  # things in TensorFlow to customize our training loop. You can look up these\n",
    "  # GradientTape related things as you are interested, but they allow us to\n",
    "  # define this custom training loop.\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    \n",
    "    # Generate images with the generator.\n",
    "    generated_images = generator(noise, training=True)\n",
    "\n",
    "    # Make predictions with the discriminator.\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    # Calculate our generator and discriminator loss.\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "  # Calculate gradients.\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "  # Update our parameters.\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "048SC6x-zmNY"
   },
   "outputs": [],
   "source": [
    "# generate_and_save_images will help us save generated images so that we can\n",
    "# view results in a convenient way.\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVc2FoPzgpMC"
   },
   "outputs": [],
   "source": [
    "# train leverages our custom training step to train our GAN.\n",
    "def train(dataset, epochs):\n",
    "\n",
    "  # loop over epochs\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for an output GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "vsIZbHxagxJy",
    "outputId": "118f091a-44cf-4e46-9db0-bfa6be7fea4f"
   },
   "outputs": [],
   "source": [
    "# Let's finally train this thing! As the training occurs, we will occasionally\n",
    "# print out an example generated image for the same random input.\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L3p4SUwKYLt"
   },
   "source": [
    "# Create a pretty GIF of the generated image at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1Hhm99UGh1F"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "fYGfykR5oFZK",
    "outputId": "b5ba6e7b-e243-419d-bc02-27c2ceb6af6c"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze6wIgLu0r6P"
   },
   "outputs": [],
   "source": [
    "anim_file = 'gan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "  display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7vb6kHT2jnM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sota_example3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
